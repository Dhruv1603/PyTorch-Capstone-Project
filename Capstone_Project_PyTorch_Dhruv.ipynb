{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required lib\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.optim as optim\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "1UyxWU_rXMVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "cBsUekAlXlSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6287243b-8443-4644-85b5-af9d35936507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "\n",
        "train_labels_path = '/content/drive/MyDrive/Human Action Recognition/Training_set.csv'\n",
        "train_images_path = '/content/drive/MyDrive/Human Action Recognition/train'\n"
      ],
      "metadata": {
        "id": "5bYKlgFoW5Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV File\n",
        "\n",
        "train_labels = pd.read_csv(train_labels_path)\n"
      ],
      "metadata": {
        "id": "jGP1UIolXG__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select randomly 100 images from each class with their respective labels\n",
        "\n",
        "def balanced_subset(df, n_samples):\n",
        "  dfs = []\n",
        "  for label in df['label'].unique():\n",
        "    subset = df[df['label'] == label]\n",
        "    sampled_subset = resample(subset, replace=False, n_samples=n_samples, random_state=42)\n",
        "    dfs.append(sampled_subset)\n",
        "  return pd.concat(dfs)\n",
        "\n",
        "balanced_train_labels = balanced_subset(train_labels, 100)\n",
        "print(balanced_train_labels['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwWiAhYAKV3w",
        "outputId": "b3013086-e18e-4356-edda-241ebaa5f9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "sitting               100\n",
            "using_laptop          100\n",
            "hugging               100\n",
            "sleeping              100\n",
            "drinking              100\n",
            "clapping              100\n",
            "dancing               100\n",
            "cycling               100\n",
            "calling               100\n",
            "laughing              100\n",
            "eating                100\n",
            "fighting              100\n",
            "listening_to_music    100\n",
            "running               100\n",
            "texting               100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert label into numeric\n",
        "\n",
        "le = LabelEncoder()\n",
        "balanced_train_labels['label'] = le.fit_transform(balanced_train_labels['label'])\n",
        "print(balanced_train_labels['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNfBL2KbKI47",
        "outputId": "3343e51d-2814-42af-ecb8-372c67679e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "11    100\n",
            "14    100\n",
            "7     100\n",
            "12    100\n",
            "4     100\n",
            "1     100\n",
            "3     100\n",
            "2     100\n",
            "0     100\n",
            "8     100\n",
            "5     100\n",
            "6     100\n",
            "9     100\n",
            "10    100\n",
            "13    100\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing\n",
        "\n",
        "class HumanActionDataset(Dataset):\n",
        "  def __init__(self, labels_df, images_path, transform=None):\n",
        "    self.labels_df = labels_df\n",
        "    self.images_path = images_path\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels_df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    img_name = self.labels_df.iloc[idx, 0]\n",
        "    image = Image.open(f'{self.images_path}/{img_name}')\n",
        "    label = self.labels_df.iloc[idx, 1]\n",
        "\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = HumanActionDataset(balanced_train_labels, train_images_path, transform=data_transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "EYui2e-4KIzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN Model\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(32)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(64)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "    self.relu4 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.fc2 = nn.Linear(512, 15)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "    x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "    x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
        "    x = x.view(-1, 64 * 8 * 8)\n",
        "    x = self.dropout(self.relu4(self.fc1(x)))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = CNN()\n"
      ],
      "metadata": {
        "id": "iMwKLaY8MAvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select loss function and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  epoch_loss = running_loss / len(train_dataloader)\n",
        "  epoch_acc = 100 * correct / total\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUIZcvxbMeye",
        "outputId": "423b1297-44b2-4205-de6a-945cbdd8b730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.7710, Accuracy: 41.19%\n",
            "Epoch 2, Loss: 1.6754, Accuracy: 40.71%\n",
            "Epoch 3, Loss: 1.5997, Accuracy: 43.33%\n",
            "Epoch 4, Loss: 1.5874, Accuracy: 43.81%\n",
            "Epoch 5, Loss: 1.4327, Accuracy: 49.52%\n",
            "Epoch 6, Loss: 1.5453, Accuracy: 44.29%\n",
            "Epoch 7, Loss: 1.4784, Accuracy: 48.10%\n",
            "Epoch 8, Loss: 1.3795, Accuracy: 50.71%\n",
            "Epoch 9, Loss: 1.3392, Accuracy: 49.76%\n",
            "Epoch 10, Loss: 1.3440, Accuracy: 51.67%\n",
            "Epoch 11, Loss: 1.2939, Accuracy: 51.19%\n",
            "Epoch 12, Loss: 1.2338, Accuracy: 55.24%\n",
            "Epoch 13, Loss: 1.2591, Accuracy: 54.52%\n",
            "Epoch 14, Loss: 1.2835, Accuracy: 52.62%\n",
            "Epoch 15, Loss: 1.1073, Accuracy: 60.95%\n",
            "Epoch 16, Loss: 1.1366, Accuracy: 58.81%\n",
            "Epoch 17, Loss: 1.1424, Accuracy: 56.90%\n",
            "Epoch 18, Loss: 1.0984, Accuracy: 59.29%\n",
            "Epoch 19, Loss: 1.1633, Accuracy: 57.62%\n",
            "Epoch 20, Loss: 1.0717, Accuracy: 58.57%\n",
            "Epoch 21, Loss: 1.0696, Accuracy: 60.48%\n",
            "Epoch 22, Loss: 0.9589, Accuracy: 64.52%\n",
            "Epoch 23, Loss: 0.9394, Accuracy: 65.71%\n",
            "Epoch 24, Loss: 0.9409, Accuracy: 63.57%\n",
            "Epoch 25, Loss: 0.9983, Accuracy: 63.10%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter search space\n",
        "\n",
        "learning_rates = [1e-3, 1e-4, 1e-5]\n",
        "batch_sizes = [4, 8, 16]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Iterate over the hyperparameter combinations\n",
        "for lr in learning_rates:\n",
        "  for batch_size in batch_sizes:\n",
        "    # Create a new model instance\n",
        "    model = CNN()\n",
        "\n",
        "    # Define the optimizer and loss function\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train the model\n",
        "    num_epochs = 25\n",
        "    for epoch in range(num_epochs):\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(train_dataloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      epoch_loss = running_loss / len(train_dataloader)\n",
        "      print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Learning Rate: {lr}, Batch Size: {batch_size}')\n",
        "\n",
        "    # Update the best parameters if the current accuracy is higher\n",
        "    if accuracy > best_accuracy:\n",
        "      best_accuracy = accuracy\n",
        "      best_params = {'lr': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIDl-5FuPgjn",
        "outputId": "8972fef6-592c-402c-b74a-77e6a200f284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.8670\n",
            "Epoch 2, Loss: 2.7629\n",
            "Epoch 3, Loss: 2.6331\n",
            "Epoch 4, Loss: 2.5512\n",
            "Epoch 5, Loss: 2.4492\n",
            "Epoch 6, Loss: 2.4680\n",
            "Epoch 7, Loss: 2.4013\n",
            "Epoch 8, Loss: 2.2838\n",
            "Epoch 9, Loss: 2.2377\n",
            "Epoch 10, Loss: 2.1428\n",
            "Epoch 11, Loss: 2.0980\n",
            "Epoch 12, Loss: 1.9617\n",
            "Epoch 13, Loss: 1.7862\n",
            "Epoch 14, Loss: 1.6961\n",
            "Epoch 15, Loss: 1.6602\n",
            "Epoch 16, Loss: 1.4866\n",
            "Epoch 17, Loss: 1.3734\n",
            "Epoch 18, Loss: 1.3643\n",
            "Epoch 19, Loss: 1.1661\n",
            "Epoch 20, Loss: 1.2634\n",
            "Epoch 21, Loss: 1.0857\n",
            "Epoch 22, Loss: 1.0001\n",
            "Epoch 23, Loss: 1.0005\n",
            "Epoch 24, Loss: 1.0170\n",
            "Epoch 25, Loss: 0.7851\n",
            "Learning Rate: 0.001, Batch Size: 4\n",
            "Epoch 1, Loss: 4.5899\n",
            "Epoch 2, Loss: 2.8229\n",
            "Epoch 3, Loss: 2.6204\n",
            "Epoch 4, Loss: 2.5632\n",
            "Epoch 5, Loss: 2.5352\n",
            "Epoch 6, Loss: 2.3736\n",
            "Epoch 7, Loss: 2.3667\n",
            "Epoch 8, Loss: 2.1664\n",
            "Epoch 9, Loss: 2.1270\n",
            "Epoch 10, Loss: 2.0274\n",
            "Epoch 11, Loss: 2.0045\n",
            "Epoch 12, Loss: 1.8979\n",
            "Epoch 13, Loss: 1.7180\n",
            "Epoch 14, Loss: 1.6721\n",
            "Epoch 15, Loss: 1.5046\n",
            "Epoch 16, Loss: 1.3752\n",
            "Epoch 17, Loss: 1.3525\n",
            "Epoch 18, Loss: 1.4034\n",
            "Epoch 19, Loss: 1.1714\n",
            "Epoch 20, Loss: 1.0953\n",
            "Epoch 21, Loss: 0.9968\n",
            "Epoch 22, Loss: 0.8656\n",
            "Epoch 23, Loss: 0.7820\n",
            "Epoch 24, Loss: 0.7589\n",
            "Epoch 25, Loss: 0.7664\n",
            "Learning Rate: 0.001, Batch Size: 8\n",
            "Epoch 1, Loss: 4.0244\n",
            "Epoch 2, Loss: 2.6730\n",
            "Epoch 3, Loss: 2.6077\n",
            "Epoch 4, Loss: 2.6104\n",
            "Epoch 5, Loss: 2.5745\n",
            "Epoch 6, Loss: 2.4860\n",
            "Epoch 7, Loss: 2.3977\n",
            "Epoch 8, Loss: 2.4250\n",
            "Epoch 9, Loss: 2.3247\n",
            "Epoch 10, Loss: 2.2144\n",
            "Epoch 11, Loss: 2.1679\n",
            "Epoch 12, Loss: 2.0932\n",
            "Epoch 13, Loss: 2.0556\n",
            "Epoch 14, Loss: 2.0656\n",
            "Epoch 15, Loss: 1.8275\n",
            "Epoch 16, Loss: 1.6498\n",
            "Epoch 17, Loss: 1.4500\n",
            "Epoch 18, Loss: 1.5537\n",
            "Epoch 19, Loss: 1.4318\n",
            "Epoch 20, Loss: 1.2973\n",
            "Epoch 21, Loss: 1.2750\n",
            "Epoch 22, Loss: 1.2771\n",
            "Epoch 23, Loss: 1.2691\n",
            "Epoch 24, Loss: 1.1492\n",
            "Epoch 25, Loss: 1.0798\n",
            "Learning Rate: 0.001, Batch Size: 16\n",
            "Epoch 1, Loss: 2.9306\n",
            "Epoch 2, Loss: 2.6057\n",
            "Epoch 3, Loss: 2.4563\n",
            "Epoch 4, Loss: 2.3493\n",
            "Epoch 5, Loss: 2.0882\n",
            "Epoch 6, Loss: 1.8837\n",
            "Epoch 7, Loss: 1.6163\n",
            "Epoch 8, Loss: 1.5289\n",
            "Epoch 9, Loss: 1.2940\n",
            "Epoch 10, Loss: 1.2010\n",
            "Epoch 11, Loss: 0.9015\n",
            "Epoch 12, Loss: 0.9037\n",
            "Epoch 13, Loss: 0.7550\n",
            "Epoch 14, Loss: 0.5917\n",
            "Epoch 15, Loss: 0.5151\n",
            "Epoch 16, Loss: 0.4750\n",
            "Epoch 17, Loss: 0.3715\n",
            "Epoch 18, Loss: 0.2897\n",
            "Epoch 19, Loss: 0.2763\n",
            "Epoch 20, Loss: 0.2606\n",
            "Epoch 21, Loss: 0.2113\n",
            "Epoch 22, Loss: 0.1849\n",
            "Epoch 23, Loss: 0.1500\n",
            "Epoch 24, Loss: 0.1528\n",
            "Epoch 25, Loss: 0.1240\n",
            "Learning Rate: 0.0001, Batch Size: 4\n",
            "Epoch 1, Loss: 2.8931\n",
            "Epoch 2, Loss: 2.6073\n",
            "Epoch 3, Loss: 2.4278\n",
            "Epoch 4, Loss: 2.2061\n",
            "Epoch 5, Loss: 2.0220\n",
            "Epoch 6, Loss: 1.7866\n",
            "Epoch 7, Loss: 1.5947\n",
            "Epoch 8, Loss: 1.4607\n",
            "Epoch 9, Loss: 1.2661\n",
            "Epoch 10, Loss: 1.0868\n",
            "Epoch 11, Loss: 0.9798\n",
            "Epoch 12, Loss: 0.7657\n",
            "Epoch 13, Loss: 0.7155\n",
            "Epoch 14, Loss: 0.6034\n",
            "Epoch 15, Loss: 0.4858\n",
            "Epoch 16, Loss: 0.4591\n",
            "Epoch 17, Loss: 0.3829\n",
            "Epoch 18, Loss: 0.3355\n",
            "Epoch 19, Loss: 0.2656\n",
            "Epoch 20, Loss: 0.2577\n",
            "Epoch 21, Loss: 0.1996\n",
            "Epoch 22, Loss: 0.1999\n",
            "Epoch 23, Loss: 0.1714\n",
            "Epoch 24, Loss: 0.1394\n",
            "Epoch 25, Loss: 0.1248\n",
            "Learning Rate: 0.0001, Batch Size: 8\n",
            "Epoch 1, Loss: 2.8535\n",
            "Epoch 2, Loss: 2.6344\n",
            "Epoch 3, Loss: 2.4328\n",
            "Epoch 4, Loss: 2.2846\n",
            "Epoch 5, Loss: 2.0780\n",
            "Epoch 6, Loss: 1.9393\n",
            "Epoch 7, Loss: 1.7694\n",
            "Epoch 8, Loss: 1.5045\n",
            "Epoch 9, Loss: 1.2927\n",
            "Epoch 10, Loss: 1.1686\n",
            "Epoch 11, Loss: 1.0286\n",
            "Epoch 12, Loss: 0.9159\n",
            "Epoch 13, Loss: 0.7821\n",
            "Epoch 14, Loss: 0.6406\n",
            "Epoch 15, Loss: 0.5577\n",
            "Epoch 16, Loss: 0.4636\n",
            "Epoch 17, Loss: 0.4387\n",
            "Epoch 18, Loss: 0.3608\n",
            "Epoch 19, Loss: 0.3067\n",
            "Epoch 20, Loss: 0.2365\n",
            "Epoch 21, Loss: 0.2275\n",
            "Epoch 22, Loss: 0.2278\n",
            "Epoch 23, Loss: 0.1585\n",
            "Epoch 24, Loss: 0.1492\n",
            "Epoch 25, Loss: 0.1338\n",
            "Learning Rate: 0.0001, Batch Size: 16\n",
            "Epoch 1, Loss: 2.7671\n",
            "Epoch 2, Loss: 2.6613\n",
            "Epoch 3, Loss: 2.6147\n",
            "Epoch 4, Loss: 2.5747\n",
            "Epoch 5, Loss: 2.4947\n",
            "Epoch 6, Loss: 2.4150\n",
            "Epoch 7, Loss: 2.3662\n",
            "Epoch 8, Loss: 2.3542\n",
            "Epoch 9, Loss: 2.2709\n",
            "Epoch 10, Loss: 2.2077\n",
            "Epoch 11, Loss: 2.1360\n",
            "Epoch 12, Loss: 2.0929\n",
            "Epoch 13, Loss: 2.0655\n",
            "Epoch 14, Loss: 1.9859\n",
            "Epoch 15, Loss: 1.9165\n",
            "Epoch 16, Loss: 1.8676\n",
            "Epoch 17, Loss: 1.8274\n",
            "Epoch 18, Loss: 1.7808\n",
            "Epoch 19, Loss: 1.7245\n",
            "Epoch 20, Loss: 1.7123\n",
            "Epoch 21, Loss: 1.6260\n",
            "Epoch 22, Loss: 1.5832\n",
            "Epoch 23, Loss: 1.5304\n",
            "Epoch 24, Loss: 1.5201\n",
            "Epoch 25, Loss: 1.4810\n",
            "Learning Rate: 1e-05, Batch Size: 4\n",
            "Epoch 1, Loss: 2.7773\n",
            "Epoch 2, Loss: 2.7057\n",
            "Epoch 3, Loss: 2.6060\n",
            "Epoch 4, Loss: 2.5953\n",
            "Epoch 5, Loss: 2.4950\n",
            "Epoch 6, Loss: 2.4536\n",
            "Epoch 7, Loss: 2.4180\n",
            "Epoch 8, Loss: 2.3503\n",
            "Epoch 9, Loss: 2.3008\n",
            "Epoch 10, Loss: 2.2280\n",
            "Epoch 11, Loss: 2.2170\n",
            "Epoch 12, Loss: 2.1893\n",
            "Epoch 13, Loss: 2.0968\n",
            "Epoch 14, Loss: 2.0284\n",
            "Epoch 15, Loss: 1.9980\n",
            "Epoch 16, Loss: 1.9616\n",
            "Epoch 17, Loss: 1.9207\n",
            "Epoch 18, Loss: 1.8617\n",
            "Epoch 19, Loss: 1.7898\n",
            "Epoch 20, Loss: 1.7172\n",
            "Epoch 21, Loss: 1.7126\n",
            "Epoch 22, Loss: 1.6566\n",
            "Epoch 23, Loss: 1.5998\n",
            "Epoch 24, Loss: 1.5316\n",
            "Epoch 25, Loss: 1.5157\n",
            "Learning Rate: 1e-05, Batch Size: 8\n",
            "Epoch 1, Loss: 2.7733\n",
            "Epoch 2, Loss: 2.6474\n",
            "Epoch 3, Loss: 2.6063\n",
            "Epoch 4, Loss: 2.5212\n",
            "Epoch 5, Loss: 2.4850\n",
            "Epoch 6, Loss: 2.4442\n",
            "Epoch 7, Loss: 2.3442\n",
            "Epoch 8, Loss: 2.3464\n",
            "Epoch 9, Loss: 2.2514\n",
            "Epoch 10, Loss: 2.1909\n",
            "Epoch 11, Loss: 2.1593\n",
            "Epoch 12, Loss: 2.1008\n",
            "Epoch 13, Loss: 2.0540\n",
            "Epoch 14, Loss: 1.9861\n",
            "Epoch 15, Loss: 1.9574\n",
            "Epoch 16, Loss: 1.9222\n",
            "Epoch 17, Loss: 1.8581\n",
            "Epoch 18, Loss: 1.7584\n",
            "Epoch 19, Loss: 1.7765\n",
            "Epoch 20, Loss: 1.6902\n",
            "Epoch 21, Loss: 1.6542\n",
            "Epoch 22, Loss: 1.6248\n",
            "Epoch 23, Loss: 1.5651\n",
            "Epoch 24, Loss: 1.4737\n",
            "Epoch 25, Loss: 1.4707\n",
            "Learning Rate: 1e-05, Batch Size: 16\n",
            "Best Hyperparameters: {'lr': 0.0001, 'batch_size': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set with the best parameters\n",
        "\n",
        "model = CNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_params['lr'])\n",
        "\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  epoch_loss = running_loss / len(train_dataloader)\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "print(f'Final Accuracy: {epoch_acc:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUBDn7QMLsr5",
        "outputId": "9bff601d-aa60-4611-e14d-044b7c0ee117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8902\n",
            "Epoch 2, Loss: 2.5921\n",
            "Epoch 3, Loss: 2.3931\n",
            "Epoch 4, Loss: 2.2716\n",
            "Epoch 5, Loss: 2.0722\n",
            "Epoch 6, Loss: 1.8744\n",
            "Epoch 7, Loss: 1.6518\n",
            "Epoch 8, Loss: 1.5268\n",
            "Epoch 9, Loss: 1.3604\n",
            "Epoch 10, Loss: 1.1748\n",
            "Epoch 11, Loss: 1.0575\n",
            "Epoch 12, Loss: 0.9309\n",
            "Epoch 13, Loss: 0.7957\n",
            "Epoch 14, Loss: 0.6400\n",
            "Epoch 15, Loss: 0.6018\n",
            "Epoch 16, Loss: 0.4909\n",
            "Epoch 17, Loss: 0.3836\n",
            "Epoch 18, Loss: 0.3433\n",
            "Epoch 19, Loss: 0.3232\n",
            "Epoch 20, Loss: 0.2880\n",
            "Epoch 21, Loss: 0.2380\n",
            "Epoch 22, Loss: 0.2028\n",
            "Epoch 23, Loss: 0.1676\n",
            "Epoch 24, Loss: 0.1672\n",
            "Epoch 25, Loss: 0.1365\n",
            "Final Accuracy: 82.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning the model architecture\n",
        "\n",
        "class CNN_FineTuned(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_FineTuned, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(128 * 8 * 8, 1024)\n",
        "    self.relu4 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.fc2 = nn.Linear(1024, 15)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "    x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "    x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
        "    x = x.view(-1, 128 * 8 * 8)\n",
        "    x = self.dropout(self.relu4(self.fc1(x)))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = CNN_FineTuned()\n",
        "\n",
        "# Trying a different optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=best_params['lr'], momentum=0.9)\n",
        "\n",
        "# Implementing learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "8DH8IS1R79qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  epoch_loss = running_loss / len(train_dataloader)\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
        "  scheduler.step()\n",
        "\n",
        "print(f'Final Accuracy: {epoch_acc:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo8L6ij0PCwo",
        "outputId": "ade51de0-9911-410e-b3b0-7c8b5066e80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0694\n",
            "Epoch 2, Loss: 1.0904\n",
            "Epoch 3, Loss: 1.0536\n",
            "Epoch 4, Loss: 1.0420\n",
            "Epoch 5, Loss: 1.0800\n",
            "Epoch 6, Loss: 1.0417\n",
            "Epoch 7, Loss: 1.0871\n",
            "Epoch 8, Loss: 1.0368\n",
            "Epoch 9, Loss: 1.0519\n",
            "Epoch 10, Loss: 1.0681\n",
            "Epoch 11, Loss: 1.0558\n",
            "Epoch 12, Loss: 1.0470\n",
            "Epoch 13, Loss: 1.0265\n",
            "Epoch 14, Loss: 1.0414\n",
            "Epoch 15, Loss: 1.0325\n",
            "Epoch 16, Loss: 1.0770\n",
            "Epoch 17, Loss: 1.0949\n",
            "Epoch 18, Loss: 1.0516\n",
            "Epoch 19, Loss: 1.0279\n",
            "Epoch 20, Loss: 1.0535\n",
            "Epoch 21, Loss: 1.0322\n",
            "Epoch 22, Loss: 1.0443\n",
            "Epoch 23, Loss: 1.0494\n",
            "Epoch 24, Loss: 1.0196\n",
            "Epoch 25, Loss: 1.0646\n",
            "Final Accuracy: 82.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_dataloader:\n",
        "    images, labels = data\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Final Accuracy: {epoch_acc:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSvtQbvoRP1S",
        "outputId": "27086638-dcbf-459c-d131-9881bfb8fec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 82.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reference: https://medium.com/bitgrit-data-science-publication/building-an-image-classification-model-with-pytorch-from-scratch-f10452073212\n",
        "# Reference: https://www.kaggle.com/code/arnoldyanga/image-classification-using-pytorch\n",
        "# Reference: https://medium.com/thecyphy/train-cnn-model-with-pytorch-21dafb918f48\n",
        "# Reference: https://towardsdatascience.com/pytorch-vision-multiclass-image-classification-531025193aa\n",
        "# Reference: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n"
      ],
      "metadata": {
        "id": "HuUoJysBRwJ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}